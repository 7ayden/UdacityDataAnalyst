{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flagged Persons of Interest: 18\n",
      "Number of features per person: 21\n",
      "Number of people without POI flag: 128\n",
      "Total Number of people: 146\n",
      "Number of   104 Total index\n",
      "Number of  101 travel agency in the park\n",
      "LOCKHART EUGENE E  {'salary': 'NaN', 'to_messages': 'NaN', 'deferral_payments': 'NaN', 'total_payments': 'NaN', 'exercised_stock_options': 'NaN', 'bonus': 'NaN', 'restricted_stock': 'NaN', 'shared_receipt_with_poi': 'NaN', 'restricted_stock_deferred': 'NaN', 'total_stock_value': 'NaN', 'expenses': 'NaN', 'loan_advances': 'NaN', 'from_messages': 'NaN', 'other': 'NaN', 'from_this_person_to_poi': 'NaN', 'poi': False, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 'NaN', 'email_address': 'NaN', 'from_poi_to_this_person': 'NaN'}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from time import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "#from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "from time import time\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df= pd.DataFrame(data_dict)\n",
    "POI_count = 0\n",
    "name_list = data_dict.keys()\n",
    "for person in name_list:\n",
    "    POI_count += data_dict[person]['poi']    \n",
    "print('Number of flagged Persons of Interest: %d' % POI_count)\n",
    "print(\"Number of features per person: %d\"%len(list(data_dict.values())[0]))\n",
    "print('Number of people without POI flag: %d' % (len(name_list) - POI_count))\n",
    "print('Total Number of people: %d' % len(df.keys()))\n",
    "#print(\"Number of features per person: %d\"%len(list(data_dict[person].count))\n",
    "total_index = data_dict.keys().index(\"TOTAL\")\n",
    "print \"Number of  \", (total_index), \"Total index\"\n",
    "travel_index = data_dict.keys().index(\"THE TRAVEL AGENCY IN THE PARK\")\n",
    "print \"Number of \", (travel_index), \"travel agency in the park\"\n",
    "print \"LOCKHART EUGENE E \", data_dict['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SKILLING JEFFREY K', 1111258), ('LAY KENNETH L', 1072321), ('FREVERT MARK A', 1060932), ('PICKERING MARK R', 655037)]\n",
      "SKILLING JEFFREY K\n",
      "LAY KENNETH L\n"
     ]
    }
   ],
   "source": [
    "### from the dataset removed, also I correct the outliers with the pdf value.\n",
    "data_dict['BELFER ROBERT']['deferred_income'] = -102500\n",
    "data_dict['BELFER ROBERT']['deferral_payments'] = 0\n",
    "data_dict['BELFER ROBERT']['expenses'] = 3285\n",
    "data_dict['BELFER ROBERT']['director_fees'] = 102500\n",
    "data_dict['BELFER ROBERT']['total_payments'] = 3285\n",
    "data_dict['BELFER ROBERT']['exercised_stock_options'] = 0\n",
    "data_dict['BELFER ROBERT']['restricted_stock'] = 44093\n",
    "data_dict['BELFER ROBERT']['restricted_stock_deferred'] = -44093\n",
    "data_dict['BELFER ROBERT']['total_stock_value'] = 0\n",
    "\n",
    "data_dict['BHATNAGAR SANJAY']['other'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['expenses'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['director_fees'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['total_payments'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['exercised_stock_options'] = 15456290\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock'] = 2604490\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock_deferred'] = -2604490\n",
    "data_dict['BHATNAGAR SANJAY']['total_stock_value'] = 15456290\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data_dict.pop(\"THE TRAVEL AGENCY IN THE PARK\", 0)\n",
    "data_dict.pop('LOCKHART EUGENE E')\n",
    "\n",
    "data = featureFormat(data_dict, features_list) \n",
    "\n",
    "### remove NAN's from dataset\n",
    "outliers = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['salary']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers.append((key, int(val)))\n",
    "\n",
    "outliers_final = (sorted(outliers,key=lambda x:x[1],reverse=True)[:4])\n",
    "### print top 4 salaries\n",
    "print outliers_final\n",
    "\n",
    "for name in outliers_final:\n",
    "    if data_dict[name[0]]['poi'] ==1:\n",
    "        print name[0]\n",
    "        \n",
    "import csv\n",
    "df.to_csv('enron_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLEN PHILLIP K                   2\n",
      "BADUM JAMES P                    15\n",
      "BANNANTINE JAMES M                5\n",
      "BAXTER JOHN C                     9\n",
      "BAY FRANKLIN R                    9\n",
      "BAZELIDES PHILIP J               13\n",
      "BECK SALLY W                      7\n",
      "BELDEN TIMOTHY N                  4\n",
      "BELFER ROBERT                    14\n",
      "BERBERIAN DAVID                  13\n",
      "BERGSIEKER RICHARD P              5\n",
      "BHATNAGAR SANJAY                  8\n",
      "BIBI PHILIPPE A                   5\n",
      "BLACHMAN JEREMY M                 5\n",
      "BLAKE JR. NORMAN P               16\n",
      "BOWEN JR RAYMOND M                5\n",
      "BROWN MICHAEL                    12\n",
      "BUCHANAN HAROLD G                 5\n",
      "BUTTS ROBERT H                   10\n",
      "BUY RICHARD B                     4\n",
      "CALGER CHRISTOPHER F              5\n",
      "CARTER REBECCA C                  6\n",
      "CAUSEY RICHARD A                  5\n",
      "CHAN RONNIE                      16\n",
      "CHRISTODOULOU DIOMEDES           16\n",
      "CLINE KENNETH W                  17\n",
      "COLWELL WESLEY                    5\n",
      "CORDES WILLIAM R                 11\n",
      "COX DAVID                         5\n",
      "CUMBERLAND MICHAEL S             12\n",
      "                                 ..\n",
      "SHANKMAN JEFFREY A                5\n",
      "SHAPIRO RICHARD S                 6\n",
      "SHARP VICTORIA T                  4\n",
      "SHELBY REX                        5\n",
      "SHERRICK JEFFREY B               11\n",
      "SHERRIFF JOHN R                   6\n",
      "SKILLING JEFFREY K                5\n",
      "STABLER FRANK                    12\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN      12\n",
      "SUNDE MARTIN                      7\n",
      "TAYLOR MITCHELL S                 7\n",
      "THE TRAVEL AGENCY IN THE PARK    18\n",
      "THORN TERENCE H                   5\n",
      "TILNEY ELIZABETH A                5\n",
      "TOTAL                             6\n",
      "UMANOFF ADAM S                   10\n",
      "URQUHART JOHN A                  16\n",
      "WAKEHAM JOHN                     17\n",
      "WALLS JR ROBERT H                 5\n",
      "WALTERS GARETH W                 15\n",
      "WASAFF GEORGE                     4\n",
      "WESTFAHL RICHARD K               11\n",
      "WHALEY DAVID A                   18\n",
      "WHALLEY LAWRENCE G                5\n",
      "WHITE JR THOMAS E                11\n",
      "WINOKUR JR. HERBERT S            16\n",
      "WODRASKA JOHN                    17\n",
      "WROBEL BRUCE                     18\n",
      "YEAGER F SCOTT                   12\n",
      "YEAP SOON                        16\n",
      "dtype: int64\n",
      "(21, 146)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy nan\n",
    "df.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "\n",
    "# Count number of NaN's for columns\n",
    "print df.isnull().sum()\n",
    "\n",
    "# DataFrame dimeansion\n",
    "print df.shape\n",
    "\n",
    "nandf = df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGBCAYAAABxZCtYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11679c350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = [\"salary\", \"bonus\"]\n",
    "#data_dict.pop('TOTAL', 0)\n",
    "data = featureFormat(data_dict, features)\n",
    "### plot features\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    plt.scatter( salary, bonus )\n",
    "\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.866666666667\n",
      "Decision tree algorithm time: 0.01 s\n",
      "Feature Ranking: \n",
      "1 feature salary (0.19722995884)\n",
      "2 feature bonus (0.189313620185)\n",
      "3 feature deferral_payments (0.174704624973)\n",
      "4 feature total_payments (0.151335953699)\n",
      "5 feature loan_advances (0.146492104387)\n",
      "6 feature restricted_stock_deferred (0.128893662728)\n",
      "7 feature deferred_income (0.012030075188)\n",
      "8 feature total_stock_value (0.0)\n",
      "9 feature expenses (0.0)\n",
      "10 feature exercised_stock_options (0.0)\n"
     ]
    }
   ],
   "source": [
    "features_list = [\"poi\", \"salary\", \"bonus\",'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "### split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### split data into training and testing datasets\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "print 'accuracy', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.733333333333\n",
      "Decision tree algorithm time: 0.002 s\n",
      "Feature Ranking: \n",
      "1 feature salary (0.215235391175)\n",
      "2 feature bonus (0.189313620185)\n",
      "3 feature deferral_payments (0.163810887764)\n",
      "4 feature total_payments (0.163366028887)\n",
      "5 feature loan_advances (0.143762958004)\n",
      "6 feature restricted_stock_deferred (0.0710441131494)\n",
      "7 feature deferred_income (0.0534670008354)\n",
      "8 feature total_stock_value (0.0)\n",
      "9 feature expenses (0.0)\n",
      "10 feature exercised_stock_options (0.0)\n"
     ]
    }
   ],
   "source": [
    "features_list = [\"poi\", \"salary\", \"bonus\",'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "### split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### split data into training and testing datasets\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "print 'accuracy', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: key  poi_sender_fract  not present\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a1db52f2849c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### Extract features and labels from dataset for local testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargetFeatureSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jaydenyuen/Dropbox/udacityDS16/p5/ud120-projects/tools/feature_format.pyc\u001b[0m in \u001b[0;36mtargetFeatureSplit\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "def dict_to_list(key,normalizer):\n",
    "    new_list=[]\n",
    "\n",
    "    for i in data_dict:\n",
    "        if data_dict[i][key]==\"NaN\" or data_dict[i][normalizer]==\"NaN\":\n",
    "            new_list.append(0.)\n",
    "        elif data_dict[i][key]>=0:\n",
    "            new_list.append(float(data_dict[i][key])/float(data_dict[i][normalizer]))\n",
    "    return new_list\n",
    "\n",
    "### create two lists of new features\n",
    "poi_sender_fract=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\n",
    "poi_recipient_fract=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\n",
    "\n",
    "### insert new features into data_dict\n",
    "count=0\n",
    "for i in data_dict:\n",
    "    data_dict[i][\"poi_sender_fract\"]=poi_sender_fract[count]\n",
    "    data_dict[i][\"poi_recipient_fract\"]=poi_recipient_fract[count]\n",
    "    count +=1\n",
    "\n",
    "    \n",
    "features_list = [\"poi\", \"poi_sender_fract\", \"poi_recipient_fract\"]    \n",
    "    ### store to my_dataset for easy export below\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "### these two lines extract the features specified in features_list\n",
    "### and extract them from data_dict, returning a numpy array\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "\n",
    "### plot new features\n",
    "for point in data:\n",
    "    from_poi = point[1]\n",
    "    to_poi = point[2]\n",
    "    plt.scatter( from_poi, to_poi )\n",
    "    if point[0] == 1:\n",
    "        plt.scatter(from_poi, to_poi, color=\"r\", marker=\"*\")\n",
    "plt.xlabel(\"fraction of emails this person gets from poi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: key  poi_sender_fract  not present\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-178186a7370f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatureFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargetFeatureSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jaydenyuen/Dropbox/udacityDS16/p5/ud120-projects/tools/feature_format.pyc\u001b[0m in \u001b[0;36mtargetFeatureSplit\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "my_features = features_list + [\n",
    "'shared_receipt_with_poi',\n",
    "'expenses',\n",
    "'loan_advances',\n",
    "'long_term_incentive',\n",
    "'other',\n",
    " 'restricted_stock',\n",
    "'restricted_stock_deferred',\n",
    "'deferral_payments',\n",
    " 'deferred_income',\n",
    "'salary',\n",
    "'total_stock_value',\n",
    "'exercised_stock_options',\n",
    "'total_payments',\n",
    "'bonus']\n",
    "\n",
    "\n",
    "features_list = [\"poi\", \"salary\", \"bonus\", \"poi_sender_fract\", \"poi_recipient_fract\",\n",
    "                 'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "k_best = SelectKBest(k=10)\n",
    "k_best.fit(features, labels)\n",
    "\n",
    "results_list = zip(k_best.get_support(), my_features[1:], k_best.scores_)\n",
    "results_list = sorted(results_list, key=lambda x: x[2], reverse=True)\n",
    "print \"K-best features:\", results_list\n",
    "\n",
    "## 5 best features chosen by SelectKBest\n",
    "my_features = features_list + ['exercised_stock_options',\n",
    "'total_stock_value',\n",
    "'bonus',\n",
    " 'salary',\n",
    "'poi_sender_fract']\n",
    "\n",
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = [\"poi\", \"poi_sender_fract\", \"poi_recipient_fract\", \"shared_receipt_with_poi\"]\n",
    "### try Naive Bayes for prediction\n",
    "t0 = time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, features, labels)\n",
    "print 'GaussianN', scores\n",
    "print 'accuracy',accuracy\n",
    "print \"NB algorithm time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f9d36ae16665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrf_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'RandomForestClassifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = sklearn.cross_validation.cross_val_score(rf_clf, features, labels)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "print 'RandomForestClassifier', scores\n",
    "print 'accuracy', accuracy\n",
    "print \"RF algorithm time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0981fecaecb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'AdaBoostClassifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, features, labels)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "print 'AdaBoostClassifier', scores \n",
    "print 'accuracy', accuracy\n",
    "print \"ABC algorithm time:\", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8cc02024ccaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-8cc02024ccaf>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m### load up student's classifier, dataset, and feature_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_classifier_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;31m### Run testing script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8cc02024ccaf>\u001b[0m in \u001b[0;36mload_classifier_and_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_classifier_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLF_PICKLE_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PICKLE_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURE_LIST_FILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    #Added min max scaler here\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    features = min_max_scaler.fit_transform(features)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            else:\n",
    "                true_positives += 1\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    pickle.dump(clf, open(CLF_PICKLE_FILENAME, \"w\") )\n",
    "    pickle.dump(dataset, open(DATASET_PICKLE_FILENAME, \"w\") )\n",
    "    pickle.dump(feature_list, open(FEATURE_LIST_FILENAME, \"w\") )\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    clf = pickle.load(open(CLF_PICKLE_FILENAME, \"r\") )\n",
    "    dataset = pickle.load(open(DATASET_PICKLE_FILENAME, \"r\") )\n",
    "    feature_list = pickle.load(open(FEATURE_LIST_FILENAME, \"r\"))\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy before tuning  0.857142857143\n",
      "Decision tree algorithm time: 0.001 s\n",
      "done in 0.001s\n",
      "Validating algorithm:\n",
      "accuracy after tuning =  0.892857142857\n",
      "precision =  0.5\n",
      "recall =  0.666666666667\n"
     ]
    }
   ],
   "source": [
    "### features_list is a list of strings, each of which is a feature name\n",
    "### first feature must be \"poi\", as this will be singled out as the label\n",
    "#features_list = [\"poi\", \"fraction_from_poi_email\", \"fraction_to_poi_email\", 'shared_receipt_with_poi']\n",
    "features_list = [\"poi\", \"poi_sender_fract\", \"poi_recipient_fract\", \"shared_receipt_with_poi\"]\n",
    "\n",
    "### store to my_dataset for easy export below\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "### these two lines extract the features specified in features_list\n",
    "### and extract them from data_dict, returning a numpy array\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "\n",
    "\n",
    "### split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "### machine learning goes here!\n",
    "### please name your classifier clf for easy export below\n",
    "\n",
    "### deploying feature selection\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "### use KFold for split and validate algorithm\n",
    "kf=KFold(len(labels),3)\n",
    "for train_indices, test_indices in kf:\n",
    "    #make training and testing sets\n",
    "    features_train= [features[ii] for ii in train_indices]\n",
    "    features_test= [features[ii] for ii in test_indices]\n",
    "    labels_train=[labels[ii] for ii in train_indices]\n",
    "    labels_test=[labels[ii] for ii in test_indices]\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "print 'accuracy before tuning ', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "### use manual tuning parameter min_samples_split\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier(min_samples_split=5)\n",
    "clf = clf.fit(features_train,labels_train)\n",
    "pred= clf.predict(features_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "\n",
    "print \"Validating algorithm:\"\n",
    "print \"accuracy after tuning = \", acc\n",
    "\n",
    "# function for calculation ratio of true positives\n",
    "# out of all positives (true + false)\n",
    "\n",
    "print 'precision = ', precision_score(labels_test,pred)\n",
    "\n",
    "# function for calculation ratio of true positives\n",
    "# out of true positives and false negatives\n",
    "\n",
    "print 'recall = ', recall_score(labels_test,pred)\n",
    "\n",
    "\n",
    "### dump your classifier, dataset and features_list so\n",
    "### anyone can run/check your results\n",
    "pickle.dump(clf, open(\"my_classifier.pkl\", \"w\") )\n",
    "pickle.dump(data_dict, open(\"my_dataset.pkl\", \"w\") )\n",
    "pickle.dump(features_list, open(\"my_feature_list.pkl\", \"w\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8\n",
      "Decision tree algorithm time: 0.001 s\n",
      "Feature Ranking: \n",
      "1 feature salary (0.189313620185)\n",
      "2 feature bonus (0.174704624973)\n",
      "3 feature deferral_payments (0.151335953699)\n",
      "4 feature total_payments (0.146492104387)\n",
      "5 feature loan_advances (0.143762958004)\n",
      "6 feature restricted_stock_deferred (0.122210287624)\n",
      "7 feature deferred_income (0.0601503759398)\n",
      "8 feature total_stock_value (0.012030075188)\n",
      "9 feature expenses (0.0)\n",
      "10 feature exercised_stock_options (0.0)\n",
      "error: key  poi_sender_fract  not present\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8afaed6b370b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m### feature in the array is the label, which is why \"poi\" must always\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m### be first in features_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargetFeatureSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m### split data into training and testing datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jaydenyuen/Dropbox/udacityDS16/p5/ud120-projects/tools/feature_format.pyc\u001b[0m in \u001b[0;36mtargetFeatureSplit\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "#!/usr/bin/python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from time import time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = [\"poi\", \"salary\", \"bonus\",'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "df= pd.DataFrame(data_dict)\n",
    "POI_count = 0\n",
    "name_list = data_dict.keys()\n",
    "for person in name_list:\n",
    "    POI_count += data_dict[person]['poi']    \n",
    "\n",
    "### from the dataset removed, also I correct the outliers with the pdf value.\n",
    "data_dict['BELFER ROBERT']['deferred_income'] = -102500\n",
    "data_dict['BELFER ROBERT']['deferral_payments'] = 0\n",
    "data_dict['BELFER ROBERT']['expenses'] = 3285\n",
    "data_dict['BELFER ROBERT']['director_fees'] = 102500\n",
    "data_dict['BELFER ROBERT']['total_payments'] = 3285\n",
    "data_dict['BELFER ROBERT']['exercised_stock_options'] = 0\n",
    "data_dict['BELFER ROBERT']['restricted_stock'] = 44093\n",
    "data_dict['BELFER ROBERT']['restricted_stock_deferred'] = -44093\n",
    "data_dict['BELFER ROBERT']['total_stock_value'] = 0\n",
    "\n",
    "data_dict['BHATNAGAR SANJAY']['other'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['expenses'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['director_fees'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['total_payments'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['exercised_stock_options'] = 15456290\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock'] = 2604490\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock_deferred'] = -2604490\n",
    "data_dict['BHATNAGAR SANJAY']['total_stock_value'] = 15456290\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data_dict.pop(\"THE TRAVEL AGENCY IN THE PARK\", 0)\n",
    "data_dict.pop('LOCKHART EUGENE E')\n",
    "\n",
    "data = featureFormat(data_dict, features_list) \n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "### remove NAN's from dataset\n",
    "outliers = []\n",
    "for key in data_dict:\n",
    "    val = data_dict[key]['salary']\n",
    "    if val == 'NaN':\n",
    "        continue\n",
    "    outliers.append((key, int(val)))\n",
    "\n",
    "outliers_final = (sorted(outliers,key=lambda x:x[1],reverse=True)[:4])\n",
    "### print top 4 salaries\n",
    "\n",
    "# Convert to numpy nan\n",
    "df.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### split data into training and testing datasets\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "print 'accuracy', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]])\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "features_list = [\"poi\", \"salary\", \"bonus\",'deferral_payments','poi_sender_fract','poi_recipient_fract', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "### split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "### split data into training and testing datasets\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "print 'accuracy', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature {} ({})\".format(i+1,features_list[i+1],importances[indices[i]])\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "def dict_to_list(key,normalizer):\n",
    "    new_list=[]\n",
    "\n",
    "    for i in data_dict:\n",
    "        if data_dict[i][key]==\"NaN\" or data_dict[i][normalizer]==\"NaN\":\n",
    "            new_list.append(0.)\n",
    "        elif data_dict[i][key]>=0:\n",
    "            new_list.append(float(data_dict[i][key])/float(data_dict[i][normalizer]))\n",
    "    return new_list\n",
    "\n",
    "### create two lists of new features\n",
    "poi_sender_fract=dict_to_list(\"from_poi_to_this_person\",\"to_messages\")\n",
    "poi_recipient_fract=dict_to_list(\"from_this_person_to_poi\",\"from_messages\")\n",
    "\n",
    "### insert new features into data_dict\n",
    "count=0\n",
    "for i in data_dict:\n",
    "    data_dict[i][\"poi_sender_fract\"]=poi_sender_fract[count]\n",
    "    data_dict[i][\"poi_recipient_fract\"]=poi_recipient_fract[count]\n",
    "    count +=1\n",
    "\n",
    "    \n",
    "features_list = [\"poi\", \"poi_sender_fract\", \"poi_recipient_fract\"]    \n",
    "    ### store to my_dataset for easy export below\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "### these two lines extract the features specified in features_list\n",
    "### and extract them from data_dict, returning a numpy array\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "\n",
    "### plot new features\n",
    "for point in data:\n",
    "    from_poi = point[1]\n",
    "    to_poi = point[2]\n",
    "    plt.scatter( from_poi, to_poi )\n",
    "    if point[0] == 1:\n",
    "        plt.scatter(from_poi, to_poi, color=\"r\", marker=\"*\")\n",
    "plt.xlabel(\"fraction of emails this person gets from poi\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "my_features = features_list + [\n",
    "'shared_receipt_with_poi',\n",
    "'expenses',\n",
    "'loan_advances',\n",
    "'long_term_incentive',\n",
    "'other',\n",
    " 'restricted_stock',\n",
    "'restricted_stock_deferred',\n",
    "'deferral_payments',\n",
    " 'deferred_income',\n",
    "'salary',\n",
    "'total_stock_value',\n",
    "'exercised_stock_options',\n",
    "'total_payments',\n",
    "'bonus']\n",
    "\n",
    "\n",
    "features_list = [\"poi\", \"salary\", \"bonus\", \"poi_sender_fract\", \"poi_recipient_fract\",\n",
    "                 'deferral_payments', 'total_payments', 'loan_advances', 'restricted_stock_deferred',\n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options',\n",
    "                 'long_term_incentive', 'shared_receipt_with_poi', 'restricted_stock', 'director_fees']\n",
    "data = featureFormat(data_dict, features_list)\n",
    "\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "k_best = SelectKBest(k=10)\n",
    "k_best.fit(features, labels)\n",
    "\n",
    "results_list = zip(k_best.get_support(), my_features[1:], k_best.scores_)\n",
    "results_list = sorted(results_list, key=lambda x: x[2], reverse=True)\n",
    "print \"K-best features:\", results_list\n",
    "\n",
    "## 5 best features chosen by SelectKBest\n",
    "my_features = features_list + ['exercised_stock_options',\n",
    "'total_stock_value',\n",
    "'bonus',\n",
    " 'salary',\n",
    "'poi_sender_fract']\n",
    "\n",
    "data = featureFormat(my_dataset, my_features, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "features_list = [\"poi\", \"poi_sender_fract\", \"poi_recipient_fract\", \"shared_receipt_with_poi\"]\n",
    "### try Naive Bayes for prediction\n",
    "t0 = time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, features, labels)\n",
    "print 'GaussianN', scores\n",
    "print 'accuracy',accuracy\n",
    "print \"NB algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10)\n",
    "scores = sklearn.cross_validation.cross_val_score(rf_clf, features, labels)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "print 'RandomForestClassifier', scores\n",
    "print 'accuracy', accuracy\n",
    "print \"RF algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, features, labels)\n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "print 'AdaBoostClassifier', scores \n",
    "print 'accuracy', accuracy\n",
    "print \"ABC algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    #Added min max scaler here\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    features = min_max_scaler.fit_transform(features)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            else:\n",
    "                true_positives += 1\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    pickle.dump(clf, open(CLF_PICKLE_FILENAME, \"w\") )\n",
    "    pickle.dump(dataset, open(DATASET_PICKLE_FILENAME, \"w\") )\n",
    "    pickle.dump(feature_list, open(FEATURE_LIST_FILENAME, \"w\") )\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    clf = pickle.load(open(CLF_PICKLE_FILENAME, \"r\") )\n",
    "    dataset = pickle.load(open(DATASET_PICKLE_FILENAME, \"r\") )\n",
    "    feature_list = pickle.load(open(FEATURE_LIST_FILENAME, \"r\"))\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "### features_list is a list of strings, each of which is a feature name\n",
    "### first feature must be \"poi\", as this will be singled out as the label\n",
    "#features_list = [\"poi\", \"fraction_from_poi_email\", \"fraction_to_poi_email\", 'shared_receipt_with_poi']\n",
    "features_list = [\"poi\", \"poi_sender_fract\", \"poi_recipient_fract\", \"shared_receipt_with_poi\"]\n",
    "\n",
    "### store to my_dataset for easy export below\n",
    "my_dataset = data_dict\n",
    "\n",
    "\n",
    "### these two lines extract the features specified in features_list\n",
    "### and extract them from data_dict, returning a numpy array\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "\n",
    "\n",
    "### split into labels and features (this line assumes that the first\n",
    "### feature in the array is the label, which is why \"poi\" must always\n",
    "### be first in features_list\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "### machine learning goes here!\n",
    "### please name your classifier clf for easy export below\n",
    "\n",
    "### deploying feature selection\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "### use KFold for split and validate algorithm\n",
    "kf=KFold(len(labels),3)\n",
    "for train_indices, test_indices in kf:\n",
    "    #make training and testing sets\n",
    "    features_train= [features[ii] for ii in train_indices]\n",
    "    features_test= [features[ii] for ii in test_indices]\n",
    "    labels_train=[labels[ii] for ii in train_indices]\n",
    "    labels_test=[labels[ii] for ii in test_indices]\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "score = clf.score(features_test,labels_test)\n",
    "print 'accuracy before tuning ', score\n",
    "\n",
    "print \"Decision tree algorithm time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "\n",
    "### use manual tuning parameter min_samples_split\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier(min_samples_split=5)\n",
    "clf = clf.fit(features_train,labels_train)\n",
    "pred= clf.predict(features_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "\n",
    "print \"Validating algorithm:\"\n",
    "print \"accuracy after tuning = \", acc\n",
    "\n",
    "# function for calculation ratio of true positives\n",
    "# out of all positives (true + false)\n",
    "\n",
    "print 'precision = ', precision_score(labels_test,pred)\n",
    "\n",
    "# function for calculation ratio of true positives\n",
    "# out of true positives and false negatives\n",
    "\n",
    "print 'recall = ', recall_score(labels_test,pred)\n",
    "\n",
    "\n",
    "### dump your classifier, dataset and features_list so\n",
    "### anyone can run/check your results\n",
    "pickle.dump(clf, open(\"my_classifier.pkl\", \"w\") )\n",
    "pickle.dump(data_dict, open(\"my_dataset.pkl\", \"w\") )\n",
    "pickle.dump(features_list, open(\"my_feature_list.pkl\", \"w\") )\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
